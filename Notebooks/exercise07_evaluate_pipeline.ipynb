{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise07 : 再トレーニングとモデル評価\n",
        "\n",
        "この演習では、機械学習パイプラインのシンプルな評価テストとして、新しいモデルと既存のモデルを比較します。新しいモデルの精度が優れている場合にのみ、そのモデルを昇格させます。そうでない場合、そのモデルは Azure Machine Learning モデルレジストリに登録されないようにします。\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. モデル評価スクリプトをファイルとして保存する (evaluate.py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "この例では、モデルの学習、モデル登録のためのパイプラインを作成します。\n",
        "このパイプラインでは、以下の手順が実行される。\n",
        "\n",
        "1. モデルの学習が行われる。\n",
        "2. モデルの精度を評価し、精度が既存のモデルを上回ればフラグを更新する。\n",
        "3. フラグに基づいてモデルをモデルレジストリに登録する。\n",
        "\n",
        "そして、各ソースコードは以下のように保存される。\n",
        "\n",
        "- training script ```./scripts/train.py```\n",
        "- evaluate script ```./scripts/evaluate.py```\n",
        "- register script ```./scripts/register_pipeline.py```\n",
        "\n",
        "モデル名（モデルディレクトリのサブフォルダ名）は、モデル情報ファイル（JSONテキスト）に保存され、次のステップに渡されます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/evaluate.py\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import mlflow\n",
        "from mlflow.pyfunc import load_model\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "def parse_args():\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model_name', type=str, help='Name under which model will be registered')\n",
        "    parser.add_argument('--model_path', type=str, help='Model directory')\n",
        "    parser.add_argument('--output_path', type=str, help=\"eval output\", default='./outputs')\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "    print(f'Arguments: {args}')\n",
        "\n",
        "    return args\n",
        "\n",
        "def main():\n",
        "\n",
        "    args = parse_args()\n",
        "\n",
        "    model_name = args.model_name\n",
        "    model_path = args.model_path\n",
        "    output_path = args.output_path\n",
        "    deploy_flag = 0\n",
        "    \n",
        "    mlflow.set_tag(\"model_name\", model_name)\n",
        "    mlflow.set_tag(\"model_path\", model_path)\n",
        "\n",
        "    # For information transfer between pipelines\n",
        "    json_open = open(model_path + \"/metric.json\", 'r')\n",
        "    json_load = json.load(json_open)\n",
        "    # Get accuracy (RMSE) from previous step Run\n",
        "    run_rmse = json_load[\"RMSE\"]\n",
        "    print(\"run_rmse: \" + str(run_rmse))\n",
        "    run_r2 = json_load[\"R2\"]\n",
        "    print(\"run_r2: \" + str(run_r2))\n",
        "\n",
        "    run_id = json_load[\"run_id\"]\n",
        "    print(\"train run_id: \" + str(run_id))\n",
        "    # Get Run executed before\n",
        "    finished_mlflow_run = mlflow.get_run(run_id)\n",
        "    # Pull metrics and tags from Run\n",
        "    metrics = finished_mlflow_run.data.metrics\n",
        "    print(metrics)\n",
        "\n",
        "    output_info = {\n",
        "        'run_rmse' : run_rmse,\n",
        "        'model_rmse' : 0,\n",
        "        'deploy_flag' : deploy_flag,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Get the latest registered models\n",
        "        client = MlflowClient() \n",
        "        model_info = client.get_registered_model(model_name)\n",
        "        print(\"model_info: \" + str(model_info.latest_versions[0]))\n",
        "        model_tags = model_info.latest_versions[0].tags\n",
        "        json_metrics = json.loads(model_tags[\"metrics\"])\n",
        "\n",
        "        # Model accuracy (RMSE)\n",
        "        model_rmse = json_metrics[\"RMSE\"]\n",
        "        output_info['model_rmse'] = model_rmse\n",
        "        print(\"model_rmse: \" + str(model_rmse))\n",
        "        \n",
        "        # RMSE Comparison\n",
        "        if run_rmse < model_rmse:\n",
        "            print(\"Improved accuracy. 精度が上回りました\")\n",
        "            deploy_flag = 1\n",
        "\n",
        "        else:\n",
        "            print(\"Accuracy did not improve. 精度が上回りませんでした\")\n",
        "            deploy_flag = 0\n",
        "    \n",
        "    except:\n",
        "        print(\"No model exists for comparison. Register the model as it is. 比較対象のモデルが存在しません。そのまま登録します。\")\n",
        "        deploy_flag = 1\n",
        "\n",
        "    output_info['run_rmse'] = run_rmse\n",
        "    output_info['run_r2'] = run_r2\n",
        "    output_info['deploy_flag'] = deploy_flag\n",
        "    mlflow.set_tag(\"deploy_flag\", deploy_flag)\n",
        "\n",
        "    output_json = json.dumps(output_info)\n",
        "    with open(output_path + \"/output_evaluate.json\", \"w\") as f:\n",
        "        f.write(output_json)\n",
        "\n",
        "    mlflow.log_artifact(output_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. パイプライン用モデル登録スクリプトをファイルとして保存する (register_pipeline.py)\r\n",
        "パイプライン実行順を指定するためにデータ入力引数を追加したバージョンです。"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/register_pipeline.py\r\n",
        "\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import mlflow\r\n",
        "from mlflow.pyfunc import load_model\r\n",
        "from mlflow.tracking import MlflowClient\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('--model_name', type=str, help='Name under which model will be registered')\r\n",
        "    parser.add_argument('--model_path', type=str, help='Model directory')\r\n",
        "    parser.add_argument('--deploy_flag', type=str, help='A deploy flag whether to deploy or no')\r\n",
        "    parser.add_argument('--eval_path', type=str, help='eval directory')\r\n",
        "    \r\n",
        "    args, _ = parser.parse_known_args()\r\n",
        "    print(f'Arguments: {args}')\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    model_name = args.model_name\r\n",
        "    model_path = args.model_path\r\n",
        "    eval_path = args.eval_path\r\n",
        "\r\n",
        "    mlflow.set_tag(\"model_name\", model_name)\r\n",
        "    mlflow.set_tag(\"model_path\", model_path)\r\n",
        "\r\n",
        "    # For information transfer between pipelines\r\n",
        "    json_open = open(eval_path + \"/output_evaluate.json\", 'r')\r\n",
        "    json_load = json.load(json_open)\r\n",
        "    run_rmse = json_load[\"run_rmse\"]\r\n",
        "    run_r2 = json_load[\"run_r2\"]\r\n",
        "    deploy_flag = json_load[\"deploy_flag\"]\r\n",
        "    print(\"run_rmse: \" + str(run_rmse))\r\n",
        "    print(\"run_r2: \" + str(run_r2))\r\n",
        "    print(\"deploy_flag: \" + str(deploy_flag))\r\n",
        "\r\n",
        "    mlflow.set_tag(\"run_rmse\", run_rmse)\r\n",
        "    mlflow.set_tag(\"run_r2\", run_r2)\r\n",
        "    mlflow.set_tag(\"deploy_flag\", deploy_flag)\r\n",
        "\r\n",
        "    if deploy_flag==1:\r\n",
        "        # Load model from model_path\r\n",
        "        model = load_model(model_path + \"/models\") \r\n",
        "        # Log the sklearn model and register as version 1\r\n",
        "        modelreg = mlflow.sklearn.log_model(\r\n",
        "            sk_model=model,\r\n",
        "            artifact_path=\"models\",\r\n",
        "            registered_model_name=model_name\r\n",
        "        )\r\n",
        "        print(modelreg)\r\n",
        "        \r\n",
        "        #Since log_model cannot register tags in models, use set_model_version_tag instead.\r\n",
        "        client = MlflowClient() \r\n",
        "        model_info = client.get_registered_model(model_name)\r\n",
        "        model_version = model_info.latest_versions[0].version\r\n",
        "        dict_metrics =  {\"RMSE\": run_rmse, \"R2\": run_r2}\r\n",
        "        client.set_model_version_tag(model_name, str(model_version), \"metrics\", json.dumps(dict_metrics))\r\n",
        "        print(\"Model registered!\")\r\n",
        "    else:\r\n",
        "        print(\"Model will not be registered!\")\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. トレーニングスクリプトをファイルとして保存する (train.py)\r\n",
        "\r\n",
        "Exercise02 で作成したトレーニングスクリプト `/scripts/train.py` を再利用します。"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. MLパイプラインの構築と実行\n",
        "\n",
        "yaml でパイプラインを構成し、生成されたパイプラインに対してジョブを投入してみましょう。\n",
        "\n",
        "> 注意 : この例では、 ``diabetes_data_oh4ml`` という名前の登録済みデータ アセットをコンピュートターゲットにマウントして使用します。\n",
        "Exercise04 よりもデータ量が増えており、精度が向上する想定のサンプルデータです。\n",
        "データ アセット準備のため、\"[Exercise00-2 : Prepare Data](./exercise00_1_prepare_data.ipynb)\" を実行します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 07_training_pipeline_job_3step.yml\r\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\r\n",
        "type: pipeline\r\n",
        "experiment_name: 07_pipeline_oh4ml_3step\r\n",
        "description: 3-Step Pipeline Example (Train, Evaluate, Register)\r\n",
        "\r\n",
        "# <inputs_and_outputs>\r\n",
        "inputs:\r\n",
        "  input: \r\n",
        "    type: uri_file\r\n",
        "    path: azureml:diabetes_data_oh4ml@latest\r\n",
        "    #path: azureml:diabetes_data_oh4ml_350records@latest\r\n",
        "  model_name: diabetes_model_oh4ml\r\n",
        "outputs: \r\n",
        "  outputs:\r\n",
        "\r\n",
        "settings:\r\n",
        "  default_datastore: azureml:workspaceblobstore\r\n",
        "  default_compute: azureml:demo-cpucluster1\r\n",
        "  continue_on_step_failure: false\r\n",
        "\r\n",
        "jobs:\r\n",
        "  train_model:\r\n",
        "    name: train_model\r\n",
        "    display_name: train-model\r\n",
        "    code: ./scripts\r\n",
        "    command: >-\r\n",
        "      python train.py \r\n",
        "      --input_data ${{inputs.diabetes_data}} \r\n",
        "      --output_dir ${{outputs.model_output}}\r\n",
        "    environment: azureml:diabetes-env@latest\r\n",
        "    inputs:\r\n",
        "      diabetes_data: ${{parent.inputs.input}}\r\n",
        "    outputs:\r\n",
        "      model_output: ${{parent.outputs.outputs}}\r\n",
        "\r\n",
        "  evaluate_model:\r\n",
        "    name: evaluate_model\r\n",
        "    display_name: evaluate-model\r\n",
        "    code: ./scripts\r\n",
        "    command: >-\r\n",
        "      python evaluate.py \r\n",
        "      --model_name ${{inputs.model_name}} \r\n",
        "      --model_path ${{inputs.model_path}} \r\n",
        "      --output_path ${{outputs.evaluate_output}}\r\n",
        "    environment: azureml:diabetes-env@latest\r\n",
        "    inputs:\r\n",
        "      model_name: ${{parent.inputs.model_name}}\r\n",
        "      model_path: ${{parent.jobs.train_model.outputs.model_output}}\r\n",
        "    outputs:\r\n",
        "      evaluate_output: \r\n",
        "\r\n",
        "  register_model:\r\n",
        "    name: register_model\r\n",
        "    display_name: register-model\r\n",
        "    code: ./scripts\r\n",
        "    command: >-\r\n",
        "      python register_pipeline.py \r\n",
        "      --model_name ${{inputs.model_name}} \r\n",
        "      --model_path ${{inputs.model_path}} \r\n",
        "      --deploy_flag ${{inputs.deploy_flag}}\r\n",
        "      --eval_path ${{inputs.eval_path}}\r\n",
        "    environment: azureml:diabetes-env@latest\r\n",
        "    inputs:\r\n",
        "      model_name: ${{parent.inputs.model_name}}\r\n",
        "      model_path: ${{parent.jobs.train_model.outputs.model_output}}\r\n",
        "      deploy_flag: 1\r\n",
        "      eval_path: ${{parent.jobs.evaluate_model.outputs.evaluate_output}}\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このパイプラインを実行するためのジョブを投入します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml job create --file 07_training_pipeline_job_3step.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "AML studio UI にアクセスし、パイプラインの結果をジョブで確認します。(下記参照)\n",
        "\n",
        "![Pipeline results](../images/006.png)\n",
        "\n",
        "パイプラインの出力でモデルメトリクスを抽出することができます。<br>\n",
        "このトレーニングパイプラインがパスされた場合、MLOps 統合の次のステージを呼び出すことができます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.  コンピュート クラスターの削除\n",
        "\n",
        "AML コンピュート クラスターは非アクティブになると自動的にノードが終了するので、コスト節約のために削除する必要はありません。しかし、もしクリーンアップしたい場合は、以下のように実行してください。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!az ml compute delete --name demo-cpucluster1 \\\n",
        "  --yes\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}